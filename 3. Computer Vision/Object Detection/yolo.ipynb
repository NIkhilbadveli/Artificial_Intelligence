{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "For object detection, YOLO (You Only Look Once) is a quite popular and fast algorithm.\n",
    "Watch Andrew NG's [lecture](https://www.youtube.com/watch?v=9s_FpMpdYW8&ab_channel=DeepLearningAI) on YOLO.\n",
    "\n",
    "The key innovation of YOLO is about looking the entire image in \"one shot\" and anchor boxes, Non-maximum suppression, and the bounding box regression. While this was the original version, subsequent versions have been improved and the model complexity increased significantly.\n",
    "\n",
    "As of this writing, the latest YOLO model is YOLOv5. And this is maintained by open source community but the original authors have stopped contributing from v3 since they believed the tech is being misused.\n",
    "\n",
    "This model is available to download from [here](https://github.com/ultralytics/yolov5). Only the default PyTorch model (.pt) is available. We have to export it to other formats (e.g. ONNX is used by OpenCV) for our use case.\n",
    "\n",
    "It is beyond the scope of this notebook to explain the model architecture and the steps to train for custom dataset with custom object classes. But, it is entirely possible if you've access to annotated images and labels. We're going to simply demonstrate how to use the YOLOv5 model to detect objects in images."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}